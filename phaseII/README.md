# Phase II: Refining interaction and designing wireframes

## Introduction

In teaching various courses there are ways that it can be conveyed. When it is in an online setting there are various media it can be presented, such as video. This project seeks to be able to develop a web platform to be able to connect students to instructors of various subjects. During the last sprint time was used to develop the backend technologies for the project to handle the various media associated with the courses.

## Methods

For the second phase, the UX team gathered informal feedback and had cognitive walkthroughs conducted on the wireframes for the application.

The UX team gave the SE team questions to ask during their MVP presentations to gather informal feedback. The questions that were asked are "Do the filters work as intended?", "Are the recommended results good enough?", and "What else do you want to see from this project?". The sample size is the class of 65 students (n = 65) who are taking the CSCI 430 course.

Three external evalutors (n = 3) conducted the cognitive walkthroughs for our wireframes that showcased the current design of the project. Specifically, the external evaluators are UX students who are not related to our project, and they did this during the "x11 Cognitive Walkthroughs" assignment. Each of the evaluators focused on the "Jayce" persona and the corresponding scenario called "Performance at the Party" during the cognitive walkthrough. The external evaluators conducted a specific style of cognitive walkthrough called the "two-question streamlined approach of [Spencer (2000)](https://learning.oreilly.com/library/view/user-interface-inspection/9780124103917/xhtml/BIB001.html#FUR85)" where they answered two questions per frame: "Will the user know what to do at this step?" and "If the user does the right thing, will the user know that they did the right thing and is making progress toward the goal?"

## Findings

!!! For each research method, detail each of the findings point-by-point to clarify new discoveries of users' needs !!!

## Conclusions

The main takeaways from the findings are the filtering system not being sophisticated enough for users to find exactly what they are looking for, having no way of verifying that the learning material is legitimate, and users having trouble determining if they are using the application correctly.

The results recommend that we do the following revisions:
1. Add user stories to determine more filters that users would like to apply on content and to find a way for users to contact teachers for extra help.
2. Make a persona and scenario for a teacher who wants to upload educational content and wants some sort of credibility check to ensure that users know their content is legitimate.
3. Improvement in displaying content to a user when they use the search functionality and picking a result to show they are using the application correctly in our wireframes.

## Caveats

With this project there were various caveats encountered that avoided the analyses from being a more accurate representation of the target audience. Some of which that are encountered are:
- The audience was not analyzed in this study: Since the target audience is not acknowledged such as taking data such as taking surveys we do not have the appropriate understanding if the needs of the target audience has been satisfied.
- The analysis was not done by a professional in Usability Design: The analyses were done by students in an undergraduate course for usability design. Details such as biases may not be mitigated with the lack of experience.
- These analyses were done by the students acting as users: With the lack of experience, the results for analyses such as the cognitive walkthrough can result in faulty data. This would then not be appropriate information to use.
- Data used are not used for the actual project: For testing the project, the information would not be the same information that would be used when the code is deployed. What is used currently is a placeholder and does not represent to the users testing the code how the application works when in production.

